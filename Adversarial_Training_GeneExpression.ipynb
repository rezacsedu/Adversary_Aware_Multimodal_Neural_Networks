{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.models import load_model\n",
    "\n",
    "from art.config import ART_DATA_PATH\n",
    "from art.utils import load_dataset, get_file\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks import FastGradientMethod\n",
    "from art.attacks import BasicIterativeMethod\n",
    "from art.defences import AdversarialTrainer\n",
    "\n",
    "import pickle\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = open('/home/rkarim/OncoNetExplainer_GE/CancerTypePrediction/TCGA_new_pre_second.pckl', 'rb')\n",
    "[dropped_genes_final, dropped_gene_name, dropped_Ens_id, samp_id_new, diag_name_new,\n",
    " project_ids_new] = pickle.load(A)\n",
    "A.close()\n",
    "\n",
    "f = open('/home/rkarim/OncoNetExplainer_GE/CancerTypePrediction/TCGA_new_pre_first.pckl', 'rb')\n",
    "[_, _, _, _, remain_cancer_ids_ind, remain_normal_ids_ind] = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(project_ids_new)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "onehot_encoded_cancer_samples = onehot_encoded[remain_cancer_ids_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer_samples_DF = pd.read_csv('/home/rkarim/OncoNetExplainer_GE/CancerTypePrediction/cancer_sample.csv', sep='\\t', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer_samples_DF_2 = X_cancer_samples_DF.iloc[:, 0:63] # 64 features\n",
    "\n",
    "X_cancer_samples_mat = np.concatenate((X_cancer_samples_DF_2,np.zeros((len(X_cancer_samples_DF_2),1))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add nine zeros to the end of each sample\n",
    "X_cancer_samples_mat = np.reshape(X_cancer_samples_mat, (-1, 8, 8))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_cancer_samples_mat, onehot_encoded_cancer_samples,\n",
    "                                                    stratify= onehot_encoded_cancer_samples,\n",
    "                                                    test_size=0.20, random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                                    stratify= y_train,\n",
    "                                                    test_size=0.1, random_state=42)\n",
    "\n",
    "num_classes = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows_train, img_cols_train = len(x_train[0][0]), len(x_train[0])\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "input_img = Input(input_shape)\n",
    "\n",
    "img_rows_test, img_cols_test = len(x_test[0][0]), len(x_test[0])\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows_test, img_cols_test, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "img_rows_val, img_cols_val = len(x_val[0][0]), len(x_val[0])\n",
    "x_val = x_val.reshape(x_val.shape[0], img_rows_val, img_cols_val, 1)\n",
    "x_val = x_val.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createKerasModel():  \n",
    "    tower_1 = Conv2D(32, (1, 8), activation='relu')(input_img)\n",
    "    tower_1 = MaxPooling2D(1, 2)(tower_1)\n",
    "    tower_1 = Flatten()(tower_1)\n",
    "\n",
    "    tower_2 = Conv2D(32, (8, 1), activation='relu')(input_img)\n",
    "    tower_2 = MaxPooling2D(1, 2)(tower_2)\n",
    "    tower_2 = Flatten()(tower_2)\n",
    "\n",
    "    output = keras.layers.concatenate([tower_1, tower_2], axis=1)\n",
    "    out1 = Dense(128, activation='relu')(output)\n",
    "    last_layer = Dense(num_classes, activation='softmax')(out1)\n",
    "    model = Model(input=[input_img], output=last_layer)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 8, 8, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 1, 32)     288         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 1, 8, 32)     288         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 4, 1, 32)     0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 1, 4, 32)     0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 128)          0           max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 128)          0           max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 256)          0           flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          32896       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 33)           4257        dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 37,729\n",
      "Trainable params: 37,729\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 2.4657 - categorical_accuracy: 0.3835 - val_loss: 1.4783 - val_categorical_accuracy: 0.6522\n",
      "Epoch 2/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.9728 - categorical_accuracy: 0.7635 - val_loss: 0.7346 - val_categorical_accuracy: 0.8370\n",
      "Epoch 3/10\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.6285 - categorical_accuracy: 0.8328 - val_loss: 0.5521 - val_categorical_accuracy: 0.8490\n",
      "Epoch 4/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5064 - categorical_accuracy: 0.8565 - val_loss: 0.5068 - val_categorical_accuracy: 0.8575\n",
      "Epoch 5/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4623 - categorical_accuracy: 0.8657 - val_loss: 0.4944 - val_categorical_accuracy: 0.8490\n",
      "Epoch 6/10\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4244 - categorical_accuracy: 0.8776 - val_loss: 0.4711 - val_categorical_accuracy: 0.8587\n",
      "Epoch 7/10\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.4075 - categorical_accuracy: 0.8689 - val_loss: 0.4500 - val_categorical_accuracy: 0.8684\n",
      "Epoch 8/10\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3794 - categorical_accuracy: 0.8827 - val_loss: 0.4405 - val_categorical_accuracy: 0.8551\n",
      "Epoch 9/10\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3573 - categorical_accuracy: 0.8918 - val_loss: 0.4346 - val_categorical_accuracy: 0.8756\n",
      "Epoch 10/10\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3576 - categorical_accuracy: 0.8858 - val_loss: 0.4136 - val_categorical_accuracy: 0.8671\n"
     ]
    }
   ],
   "source": [
    "model = createKerasModel()\n",
    "model.summary()\n",
    "\n",
    "# Create classifier wrapper\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=10, batch_size=128, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7444 samples, validate on 828 samples\n",
      "Epoch 1/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.3566 - categorical_accuracy: 0.8881 - val_loss: 0.4179 - val_categorical_accuracy: 0.8696\n",
      "Epoch 2/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.3489 - categorical_accuracy: 0.8876 - val_loss: 0.3962 - val_categorical_accuracy: 0.8792\n",
      "Epoch 3/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.3339 - categorical_accuracy: 0.8960 - val_loss: 0.4026 - val_categorical_accuracy: 0.8768\n",
      "Epoch 4/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.3310 - categorical_accuracy: 0.8976 - val_loss: 0.4054 - val_categorical_accuracy: 0.8756\n",
      "Epoch 5/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.3177 - categorical_accuracy: 0.9017 - val_loss: 0.4274 - val_categorical_accuracy: 0.8671\n",
      "Epoch 6/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.3178 - categorical_accuracy: 0.8980 - val_loss: 0.3988 - val_categorical_accuracy: 0.8841\n",
      "Epoch 7/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.3135 - categorical_accuracy: 0.9018 - val_loss: 0.3819 - val_categorical_accuracy: 0.8804\n",
      "Epoch 8/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.3057 - categorical_accuracy: 0.9013 - val_loss: 0.3969 - val_categorical_accuracy: 0.8756\n",
      "Epoch 9/100\n",
      "7444/7444 [==============================] - 0s 22us/step - loss: 0.3029 - categorical_accuracy: 0.8984 - val_loss: 0.4042 - val_categorical_accuracy: 0.8768\n",
      "Epoch 10/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2953 - categorical_accuracy: 0.9056 - val_loss: 0.4181 - val_categorical_accuracy: 0.8780\n",
      "Epoch 11/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.3022 - categorical_accuracy: 0.9041 - val_loss: 0.4094 - val_categorical_accuracy: 0.8720\n",
      "Epoch 12/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2916 - categorical_accuracy: 0.9057 - val_loss: 0.3930 - val_categorical_accuracy: 0.8696\n",
      "Epoch 13/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2767 - categorical_accuracy: 0.9093 - val_loss: 0.3984 - val_categorical_accuracy: 0.8720\n",
      "Epoch 14/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2731 - categorical_accuracy: 0.9125 - val_loss: 0.4136 - val_categorical_accuracy: 0.8708\n",
      "Epoch 15/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2735 - categorical_accuracy: 0.9142 - val_loss: 0.3923 - val_categorical_accuracy: 0.8829\n",
      "Epoch 16/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2672 - categorical_accuracy: 0.9123 - val_loss: 0.3990 - val_categorical_accuracy: 0.8659\n",
      "Epoch 17/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2658 - categorical_accuracy: 0.9119 - val_loss: 0.4155 - val_categorical_accuracy: 0.8732\n",
      "Epoch 18/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2644 - categorical_accuracy: 0.9115 - val_loss: 0.3812 - val_categorical_accuracy: 0.8708\n",
      "Epoch 19/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2551 - categorical_accuracy: 0.9178 - val_loss: 0.3842 - val_categorical_accuracy: 0.8684\n",
      "Epoch 20/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2607 - categorical_accuracy: 0.9167 - val_loss: 0.3964 - val_categorical_accuracy: 0.8720\n",
      "Epoch 21/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2442 - categorical_accuracy: 0.9205 - val_loss: 0.3849 - val_categorical_accuracy: 0.8768\n",
      "Epoch 22/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2404 - categorical_accuracy: 0.9199 - val_loss: 0.3804 - val_categorical_accuracy: 0.8744\n",
      "Epoch 23/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.2403 - categorical_accuracy: 0.9195 - val_loss: 0.3960 - val_categorical_accuracy: 0.8816\n",
      "Epoch 24/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2413 - categorical_accuracy: 0.9177 - val_loss: 0.3972 - val_categorical_accuracy: 0.8720\n",
      "Epoch 25/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.2347 - categorical_accuracy: 0.9203 - val_loss: 0.3917 - val_categorical_accuracy: 0.8732\n",
      "Epoch 26/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.2437 - categorical_accuracy: 0.9172 - val_loss: 0.4061 - val_categorical_accuracy: 0.8732\n",
      "Epoch 27/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.2302 - categorical_accuracy: 0.9229 - val_loss: 0.3826 - val_categorical_accuracy: 0.8744\n",
      "Epoch 28/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2293 - categorical_accuracy: 0.9228 - val_loss: 0.4106 - val_categorical_accuracy: 0.8623\n",
      "Epoch 29/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.2240 - categorical_accuracy: 0.9242 - val_loss: 0.3952 - val_categorical_accuracy: 0.8816\n",
      "Epoch 30/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.2164 - categorical_accuracy: 0.9265 - val_loss: 0.3916 - val_categorical_accuracy: 0.8671\n",
      "Epoch 31/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2125 - categorical_accuracy: 0.9307 - val_loss: 0.4100 - val_categorical_accuracy: 0.8744\n",
      "Epoch 32/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2086 - categorical_accuracy: 0.9297 - val_loss: 0.4082 - val_categorical_accuracy: 0.8732\n",
      "Epoch 33/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2115 - categorical_accuracy: 0.9273 - val_loss: 0.4057 - val_categorical_accuracy: 0.8744\n",
      "Epoch 34/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.2050 - categorical_accuracy: 0.9304 - val_loss: 0.3903 - val_categorical_accuracy: 0.8780\n",
      "Epoch 35/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1989 - categorical_accuracy: 0.9340 - val_loss: 0.4055 - val_categorical_accuracy: 0.8792\n",
      "Epoch 36/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1970 - categorical_accuracy: 0.9343 - val_loss: 0.3870 - val_categorical_accuracy: 0.8768\n",
      "Epoch 37/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1959 - categorical_accuracy: 0.9334 - val_loss: 0.3974 - val_categorical_accuracy: 0.8768\n",
      "Epoch 38/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1942 - categorical_accuracy: 0.9332 - val_loss: 0.3976 - val_categorical_accuracy: 0.8756\n",
      "Epoch 39/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1868 - categorical_accuracy: 0.9366 - val_loss: 0.4141 - val_categorical_accuracy: 0.8804\n",
      "Epoch 40/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1849 - categorical_accuracy: 0.9348 - val_loss: 0.4037 - val_categorical_accuracy: 0.8804\n",
      "Epoch 41/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1793 - categorical_accuracy: 0.9428 - val_loss: 0.4121 - val_categorical_accuracy: 0.8744\n",
      "Epoch 42/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1762 - categorical_accuracy: 0.9404 - val_loss: 0.4118 - val_categorical_accuracy: 0.8780\n",
      "Epoch 43/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1698 - categorical_accuracy: 0.9447 - val_loss: 0.4256 - val_categorical_accuracy: 0.8708\n",
      "Epoch 44/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1707 - categorical_accuracy: 0.9422 - val_loss: 0.4056 - val_categorical_accuracy: 0.8744\n",
      "Epoch 45/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.1666 - categorical_accuracy: 0.9413 - val_loss: 0.4362 - val_categorical_accuracy: 0.8744\n",
      "Epoch 46/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1679 - categorical_accuracy: 0.9410 - val_loss: 0.4057 - val_categorical_accuracy: 0.8816\n",
      "Epoch 47/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1638 - categorical_accuracy: 0.9460 - val_loss: 0.4494 - val_categorical_accuracy: 0.8611\n",
      "Epoch 48/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1627 - categorical_accuracy: 0.9444 - val_loss: 0.4098 - val_categorical_accuracy: 0.8841\n",
      "Epoch 49/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1548 - categorical_accuracy: 0.9471 - val_loss: 0.4254 - val_categorical_accuracy: 0.8696\n",
      "Epoch 50/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1540 - categorical_accuracy: 0.9491 - val_loss: 0.4341 - val_categorical_accuracy: 0.8696\n",
      "Epoch 51/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1536 - categorical_accuracy: 0.9477 - val_loss: 0.4218 - val_categorical_accuracy: 0.8780\n",
      "Epoch 52/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1529 - categorical_accuracy: 0.9494 - val_loss: 0.4167 - val_categorical_accuracy: 0.8804\n",
      "Epoch 53/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.1463 - categorical_accuracy: 0.9506 - val_loss: 0.4535 - val_categorical_accuracy: 0.8720\n",
      "Epoch 54/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1412 - categorical_accuracy: 0.9514 - val_loss: 0.4368 - val_categorical_accuracy: 0.8659\n",
      "Epoch 55/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1373 - categorical_accuracy: 0.9559 - val_loss: 0.4517 - val_categorical_accuracy: 0.8708\n",
      "Epoch 56/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1448 - categorical_accuracy: 0.9526 - val_loss: 0.4238 - val_categorical_accuracy: 0.8768\n",
      "Epoch 57/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.1341 - categorical_accuracy: 0.9574 - val_loss: 0.4432 - val_categorical_accuracy: 0.8708\n",
      "Epoch 58/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1294 - categorical_accuracy: 0.9578 - val_loss: 0.4587 - val_categorical_accuracy: 0.8647\n",
      "Epoch 59/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.1304 - categorical_accuracy: 0.9559 - val_loss: 0.4681 - val_categorical_accuracy: 0.8671\n",
      "Epoch 60/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1334 - categorical_accuracy: 0.9537 - val_loss: 0.4440 - val_categorical_accuracy: 0.8611\n",
      "Epoch 61/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1227 - categorical_accuracy: 0.9610 - val_loss: 0.4506 - val_categorical_accuracy: 0.8732\n",
      "Epoch 62/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1229 - categorical_accuracy: 0.9621 - val_loss: 0.4458 - val_categorical_accuracy: 0.8732\n",
      "Epoch 63/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1159 - categorical_accuracy: 0.9618 - val_loss: 0.4399 - val_categorical_accuracy: 0.8792\n",
      "Epoch 64/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1202 - categorical_accuracy: 0.9600 - val_loss: 0.4558 - val_categorical_accuracy: 0.8780\n",
      "Epoch 65/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1166 - categorical_accuracy: 0.9608 - val_loss: 0.4540 - val_categorical_accuracy: 0.8708\n",
      "Epoch 66/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.1125 - categorical_accuracy: 0.9631 - val_loss: 0.4528 - val_categorical_accuracy: 0.8780\n",
      "Epoch 67/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1146 - categorical_accuracy: 0.9617 - val_loss: 0.4753 - val_categorical_accuracy: 0.8720\n",
      "Epoch 68/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1168 - categorical_accuracy: 0.9618 - val_loss: 0.4753 - val_categorical_accuracy: 0.8756\n",
      "Epoch 69/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1020 - categorical_accuracy: 0.9667 - val_loss: 0.4586 - val_categorical_accuracy: 0.8708\n",
      "Epoch 70/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.1103 - categorical_accuracy: 0.9644 - val_loss: 0.4895 - val_categorical_accuracy: 0.8696\n",
      "Epoch 71/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1050 - categorical_accuracy: 0.9698 - val_loss: 0.4710 - val_categorical_accuracy: 0.8708\n",
      "Epoch 72/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1060 - categorical_accuracy: 0.9653 - val_loss: 0.4640 - val_categorical_accuracy: 0.8756\n",
      "Epoch 73/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1040 - categorical_accuracy: 0.9674 - val_loss: 0.4829 - val_categorical_accuracy: 0.8720\n",
      "Epoch 74/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0972 - categorical_accuracy: 0.9700 - val_loss: 0.4875 - val_categorical_accuracy: 0.8684\n",
      "Epoch 75/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.1052 - categorical_accuracy: 0.9657 - val_loss: 0.4775 - val_categorical_accuracy: 0.8720\n",
      "Epoch 76/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.0933 - categorical_accuracy: 0.9714 - val_loss: 0.4903 - val_categorical_accuracy: 0.8708\n",
      "Epoch 77/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.0954 - categorical_accuracy: 0.9700 - val_loss: 0.5089 - val_categorical_accuracy: 0.8659\n",
      "Epoch 78/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.0882 - categorical_accuracy: 0.9741 - val_loss: 0.4947 - val_categorical_accuracy: 0.8756\n",
      "Epoch 79/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0886 - categorical_accuracy: 0.9715 - val_loss: 0.5145 - val_categorical_accuracy: 0.8671\n",
      "Epoch 80/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.0824 - categorical_accuracy: 0.9745 - val_loss: 0.5146 - val_categorical_accuracy: 0.8696\n",
      "Epoch 81/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0826 - categorical_accuracy: 0.9750 - val_loss: 0.5143 - val_categorical_accuracy: 0.8744\n",
      "Epoch 82/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0818 - categorical_accuracy: 0.9750 - val_loss: 0.5036 - val_categorical_accuracy: 0.8647\n",
      "Epoch 83/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0824 - categorical_accuracy: 0.9747 - val_loss: 0.4909 - val_categorical_accuracy: 0.8792\n",
      "Epoch 84/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0742 - categorical_accuracy: 0.9785 - val_loss: 0.5106 - val_categorical_accuracy: 0.8768\n",
      "Epoch 85/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0791 - categorical_accuracy: 0.9750 - val_loss: 0.5065 - val_categorical_accuracy: 0.8744\n",
      "Epoch 86/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0759 - categorical_accuracy: 0.9766 - val_loss: 0.5046 - val_categorical_accuracy: 0.8732\n",
      "Epoch 87/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.0731 - categorical_accuracy: 0.9766 - val_loss: 0.5020 - val_categorical_accuracy: 0.8720\n",
      "Epoch 88/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0830 - categorical_accuracy: 0.9729 - val_loss: 0.5127 - val_categorical_accuracy: 0.8756\n",
      "Epoch 89/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.0700 - categorical_accuracy: 0.9801 - val_loss: 0.5479 - val_categorical_accuracy: 0.8696\n",
      "Epoch 90/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.0693 - categorical_accuracy: 0.9785 - val_loss: 0.5174 - val_categorical_accuracy: 0.8696\n",
      "Epoch 91/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0702 - categorical_accuracy: 0.9773 - val_loss: 0.5201 - val_categorical_accuracy: 0.8732\n",
      "Epoch 92/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0643 - categorical_accuracy: 0.9816 - val_loss: 0.5484 - val_categorical_accuracy: 0.8684\n",
      "Epoch 93/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.0600 - categorical_accuracy: 0.9841 - val_loss: 0.5303 - val_categorical_accuracy: 0.8732\n",
      "Epoch 94/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.0648 - categorical_accuracy: 0.9800 - val_loss: 0.5526 - val_categorical_accuracy: 0.8659\n",
      "Epoch 95/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0730 - categorical_accuracy: 0.9756 - val_loss: 0.5440 - val_categorical_accuracy: 0.8611\n",
      "Epoch 96/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0642 - categorical_accuracy: 0.9784 - val_loss: 0.5422 - val_categorical_accuracy: 0.8720\n",
      "Epoch 97/100\n",
      "7444/7444 [==============================] - 0s 20us/step - loss: 0.0628 - categorical_accuracy: 0.9785 - val_loss: 0.5420 - val_categorical_accuracy: 0.8635\n",
      "Epoch 98/100\n",
      "7444/7444 [==============================] - 0s 21us/step - loss: 0.0601 - categorical_accuracy: 0.9823 - val_loss: 0.5453 - val_categorical_accuracy: 0.8792\n",
      "Epoch 99/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0608 - categorical_accuracy: 0.9803 - val_loss: 0.5579 - val_categorical_accuracy: 0.8684\n",
      "Epoch 100/100\n",
      "7444/7444 [==============================] - 0s 19us/step - loss: 0.0565 - categorical_accuracy: 0.9828 - val_loss: 0.5512 - val_categorical_accuracy: 0.8671\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=100, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classifier\"></a>\n",
    "## 2. Train and evaluate a baseline classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the classifier model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the classifier performance on the first 100 original test samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test data (first 100 images):\n",
      "Correctly classified: 88\n",
      "Incorrectly classified: 12\n"
     ]
    }
   ],
   "source": [
    "x_test_pred = np.argmax(classifier.predict(x_test[:100]), axis=1)\n",
    "nb_correct_pred = np.sum(x_test_pred == np.argmax(y_test[:100], axis=1))\n",
    "\n",
    "print(\"Original test data (first 100 images):\")\n",
    "print(\"Correctly classified: {}\".format(nb_correct_pred))\n",
    "print(\"Incorrectly classified: {}\".format(100-nb_correct_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some adversarial samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker = FastGradientMethod(classifier, eps=0.5)\n",
    "x_test_adv = attacker.generate(x_test[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate performance on those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial test data (first 100 images):\n",
      "Correctly classified: 73\n",
      "Incorrectly classified: 27\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_pred = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "nb_correct_adv_pred = np.sum(x_test_adv_pred == np.argmax(y_test[:100], axis=1))\n",
    "\n",
    "print(\"Adversarial test data (first 100 images):\")\n",
    "print(\"Correctly classified: {}\".format(nb_correct_adv_pred))\n",
    "print(\"Incorrectly classified: {}\".format(100-nb_correct_adv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"adv_training\"></a>\n",
    "## 3. Adversarially train a robust classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRobustKerasModel():  \n",
    "    tower_1 = Conv2D(64, (1, 8), activation='relu')(input_img)\n",
    "    tower_1 = MaxPooling2D(1, 2)(tower_1)\n",
    "    tower_1 = Flatten()(tower_1)\n",
    "\n",
    "    tower_2 = Conv2D(32, (8, 1), activation='relu')(input_img)\n",
    "    tower_2 = MaxPooling2D(1, 2)(tower_2)\n",
    "    tower_2 = Flatten()(tower_2)\n",
    "    \n",
    "    tower_3 = Conv2D(16, (8, 1), activation='relu')(input_img)\n",
    "    tower_3 = MaxPooling2D(1, 2)(tower_3)\n",
    "    tower_3 = Flatten()(tower_3)\n",
    "\n",
    "    output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)\n",
    "    out1 = Dense(256, activation='relu')(output)\n",
    "    last_layer = Dense(num_classes, activation='softmax')(out1)\n",
    "    model = Model(input=[input_img], output=last_layer)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the robust classifier has the same architecture as above, except the first dense layer has **1024** instead of **128** units. (This was recommend by Madry et al. (2017), *Towards Deep Learning Models Resistant to Adversarial Attacks*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustModel = createRobustKerasModel()\n",
    "\n",
    "# Create classifier wrapper\n",
    "robust_classifier = KerasClassifier(model=robustModel, clip_values=(min_, max_))\n",
    "#robust_classifier.fit(x_train, y_train, nb_epochs=10, batch_size=128, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also as recommended by Madry et al., we use BIM/PGD attacks during adversarial training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = BasicIterativeMethod(robust_classifier, eps=0.3, eps_step=0.01, max_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform adversarial training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 3.8442 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.5669 - categorical_accuracy: 0.0078\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2755 - categorical_accuracy: 0.0547\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1765 - categorical_accuracy: 0.0938\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.1642 - categorical_accuracy: 0.1094\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.0098 - categorical_accuracy: 0.1484\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2367 - categorical_accuracy: 0.0078\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.9956 - categorical_accuracy: 0.2031\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.1189 - categorical_accuracy: 0.1875\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7935 - categorical_accuracy: 0.2578\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6775 - categorical_accuracy: 0.2969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.9761 - categorical_accuracy: 0.1797\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7208 - categorical_accuracy: 0.2891\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.8461 - categorical_accuracy: 0.3203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6625 - categorical_accuracy: 0.4766\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6848 - categorical_accuracy: 0.5781\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5774 - categorical_accuracy: 0.5625\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4945 - categorical_accuracy: 0.5625\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5234 - categorical_accuracy: 0.4141\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5080 - categorical_accuracy: 0.5469\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4672 - categorical_accuracy: 0.4531\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3040 - categorical_accuracy: 0.4141\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0483 - categorical_accuracy: 0.5000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.5650 - categorical_accuracy: 0.3203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2464 - categorical_accuracy: 0.4141\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0633 - categorical_accuracy: 0.4844\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3517 - categorical_accuracy: 0.4688\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2852 - categorical_accuracy: 0.5156\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0053 - categorical_accuracy: 0.6562\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8357 - categorical_accuracy: 0.6719\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8298 - categorical_accuracy: 0.6719\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.1479 - categorical_accuracy: 0.4844\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8192 - categorical_accuracy: 0.6641\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7547 - categorical_accuracy: 0.6484\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6655 - categorical_accuracy: 0.6094\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6019 - categorical_accuracy: 0.6328\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6921 - categorical_accuracy: 0.6172\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3319 - categorical_accuracy: 0.7266\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6364 - categorical_accuracy: 0.5781\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6678 - categorical_accuracy: 0.5859\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3852 - categorical_accuracy: 0.7578\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4364 - categorical_accuracy: 0.7188\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2835 - categorical_accuracy: 0.7188\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4742 - categorical_accuracy: 0.7344\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5399 - categorical_accuracy: 0.6484\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3580 - categorical_accuracy: 0.6953\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6980 - categorical_accuracy: 0.6094\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1377 - categorical_accuracy: 0.7812\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7293 - categorical_accuracy: 0.5781\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3335 - categorical_accuracy: 0.7188\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6330 - categorical_accuracy: 0.6328\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8750 - categorical_accuracy: 0.7891\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2941 - categorical_accuracy: 0.7031\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9901 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0920 - categorical_accuracy: 0.7578\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1826 - categorical_accuracy: 0.7188\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1480 - categorical_accuracy: 0.7109\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0907 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8588 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9666 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3038 - categorical_accuracy: 0.6406\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1912 - categorical_accuracy: 0.6953\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9288 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0981 - categorical_accuracy: 0.7109\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8830 - categorical_accuracy: 0.7891\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9119 - categorical_accuracy: 0.7344\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8645 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9328 - categorical_accuracy: 0.7656\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8843 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9084 - categorical_accuracy: 0.7578\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8293 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8636 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6877 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2525 - categorical_accuracy: 0.7266\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1222 - categorical_accuracy: 0.7344\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6405 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7640 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6818 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7359 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9753 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7961 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6937 - categorical_accuracy: 0.7656\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9316 - categorical_accuracy: 0.6953\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1113 - categorical_accuracy: 0.6953\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7470 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9155 - categorical_accuracy: 0.7812\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4992 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8142 - categorical_accuracy: 0.7578\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9281 - categorical_accuracy: 0.7422\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8965 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7762 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7421 - categorical_accuracy: 0.7578\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0621 - categorical_accuracy: 0.7109\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0616 - categorical_accuracy: 0.6641\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7233 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8017 - categorical_accuracy: 0.8125\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5878 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6222 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8571 - categorical_accuracy: 0.7656\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6998 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5016 - categorical_accuracy: 0.9219\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7203 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7729 - categorical_accuracy: 0.7891\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6501 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6302 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5972 - categorical_accuracy: 0.7891\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4890 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6956 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7855 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5533 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5854 - categorical_accuracy: 0.7891\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6616 - categorical_accuracy: 0.7812\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4765 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6128 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6037 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7689 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4926 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6524 - categorical_accuracy: 0.8500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8081 - categorical_accuracy: 0.7422\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5727 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6270 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5860 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6296 - categorical_accuracy: 0.8125\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4657 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5104 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5671 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6905 - categorical_accuracy: 0.8125\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5936 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7693 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5335 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6651 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7922 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5743 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6561 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6629 - categorical_accuracy: 0.7812\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5265 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5670 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4886 - categorical_accuracy: 0.8906\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7701 - categorical_accuracy: 0.7891\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3962 - categorical_accuracy: 0.8906\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4494 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5190 - categorical_accuracy: 0.8984\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3868 - categorical_accuracy: 0.9297\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4103 - categorical_accuracy: 0.9062\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3937 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5390 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5267 - categorical_accuracy: 0.8125\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5445 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5734 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4875 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5071 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5620 - categorical_accuracy: 0.9141\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8682 - categorical_accuracy: 0.7656\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6060 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4487 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4230 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3782 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6010 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5167 - categorical_accuracy: 0.8125\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5565 - categorical_accuracy: 0.8125\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7838 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4872 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5251 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6190 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6331 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4196 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4924 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4285 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7002 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6959 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6707 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5987 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4926 - categorical_accuracy: 0.9062\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4677 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6333 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5565 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7455 - categorical_accuracy: 0.6000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5172 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6046 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4628 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5948 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6774 - categorical_accuracy: 0.7578\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5298 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6906 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4253 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3370 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5256 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4258 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3269 - categorical_accuracy: 0.9062\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5053 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5873 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4173 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4860 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5601 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5201 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4003 - categorical_accuracy: 0.9219\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4828 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5882 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4965 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3565 - categorical_accuracy: 0.9297\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3907 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4312 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6199 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2424 - categorical_accuracy: 0.9609\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7677 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5270 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6619 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4965 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7040 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3522 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6470 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4139 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6730 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5005 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6404 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5709 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3931 - categorical_accuracy: 0.9375\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4568 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4355 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4647 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4347 - categorical_accuracy: 0.8984\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8045 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4890 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6855 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4582 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4694 - categorical_accuracy: 0.8125\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5356 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3498 - categorical_accuracy: 0.9062\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7844 - categorical_accuracy: 0.7578\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5289 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6222 - categorical_accuracy: 0.7500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4004 - categorical_accuracy: 0.8906\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6534 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4317 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3708 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1941 - categorical_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3921 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5428 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6274 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4342 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5360 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6277 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4068 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4771 - categorical_accuracy: 0.8594\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3325 - categorical_accuracy: 0.9062\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5456 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6338 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4339 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5770 - categorical_accuracy: 0.7188\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4193 - categorical_accuracy: 0.8984\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1953 - categorical_accuracy: 0.9531\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4944 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5181 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4808 - categorical_accuracy: 0.7812\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6443 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4538 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4196 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3738 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3316 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4647 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4147 - categorical_accuracy: 0.9062\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7478 - categorical_accuracy: 0.7266\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6197 - categorical_accuracy: 0.7891\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6328 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4068 - categorical_accuracy: 0.8984\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4220 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6039 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4523 - categorical_accuracy: 0.8047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4842 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6065 - categorical_accuracy: 0.7734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5118 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5663 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5446 - categorical_accuracy: 0.8203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4323 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5259 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5963 - categorical_accuracy: 0.7969\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3609 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6268 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3129 - categorical_accuracy: 0.9141\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5021 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4320 - categorical_accuracy: 0.8281\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2836 - categorical_accuracy: 0.8984\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5103 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5793 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3489 - categorical_accuracy: 0.8750\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2942 - categorical_accuracy: 0.9375\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3880 - categorical_accuracy: 0.8516\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7318 - categorical_accuracy: 0.7812\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5290 - categorical_accuracy: 0.8828\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5423 - categorical_accuracy: 0.8359\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5903 - categorical_accuracy: 0.8438\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0303 - categorical_accuracy: 0.7266\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3219 - categorical_accuracy: 0.9219\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3601 - categorical_accuracy: 0.8672\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2920 - categorical_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "# We had performed this before, starting with a randomly intialized model.\n",
    "# Adversarial training takes about 80 minutes on an NVIDIA V100.\n",
    "# The resulting model is the one loaded from mnist_cnn_robust.h5 above.\n",
    "\n",
    "# Here is the command we had used for the Adversarial Training\n",
    "\n",
    "trainer = AdversarialTrainer(robust_classifier, attacks, ratio=1.0)\n",
    "trainer.fit(x_train, y_train, nb_epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "## 4. Evaluate the robust classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the robust classifier's performance on the original test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test data (first 100 images):\n",
      "Correctly classified: 1809\n",
      "Incorrectly classified: 259\n"
     ]
    }
   ],
   "source": [
    "x_test_robust_pred = np.argmax(robust_classifier.predict(x_test), axis=1)\n",
    "nb_correct_robust_pred = np.sum(x_test_robust_pred == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(\"Original test data (first 100 images):\")\n",
    "print(\"Correctly classified: {}\".format(nb_correct_robust_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(x_test)-nb_correct_robust_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the robust classifier's performance on the adversarial test data (**white-box** setting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker_robust = FastGradientMethod(robust_classifier, eps=0.5)\n",
    "x_test_adv_robust = attacker_robust.generate(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial test data (first 100 images):\n",
      "Correctly classified: 1710\n",
      "Incorrectly classified: 358\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_robust_pred = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "nb_correct_adv_robust_pred = np.sum(x_test_adv_robust_pred == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(\"Adversarial test data (first 100 images):\")\n",
    "print(\"Correctly classified: {}\".format(nb_correct_adv_robust_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(x_test)-nb_correct_adv_robust_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of the original and the robust classifier over a range of `eps` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_range = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "nb_correct_original = []\n",
    "nb_correct_robust = []\n",
    "\n",
    "for eps in eps_range:\n",
    "    attacker.set_params(**{'eps': eps})\n",
    "    attacker_robust.set_params(**{'eps': eps})\n",
    "    x_test_adv = attacker.generate(x_test)\n",
    "    x_test_adv_robust = attacker_robust.generate(x_test)\n",
    "    \n",
    "    x_test_adv_pred = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    nb_correct_original += [np.sum(x_test_adv_pred == np.argmax(y_test, axis=1))]\n",
    "    \n",
    "    x_test_adv_robust_pred = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "    nb_correct_robust += [np.sum(x_test_adv_robust_pred == np.argmax(y_test, axis=1))]\n",
    "\n",
    "eps_range = [0] + eps_range\n",
    "nb_correct_original = [nb_correct_pred] + nb_correct_original\n",
    "nb_correct_robust = [nb_correct_robust_pred] + nb_correct_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcTfX/wPHXe2Yw1sieJRJKmzKFFpElqaRIoiKFSGhPG+nbt1QqqZRUfNtLSiGRSBtlz5IlWbOH7Mv4/P54n/nNxSxnxtx7Zu59Px+P+5h7zzn33Pdc477v+SzvjzjnMMYYE7vigg7AGGNMsCwRGGNMjLNEYIwxMc4SgTHGxDhLBMYYE+MsERhjTIyzRGCMMTHOEoExxsS4sCYCEektIgtEZKGI9PG29ReRdSIy17u1CGcMxhhjMpYQrhOLyJlAF+AC4AAwQUTGertfdM497/dcpUqVclWqVMn5II0xJorNmjVri3OudGbHhS0RAKcDM5xzewBE5HvguuycqEqVKsycOTMnYzPGmKgnIqv8HBfOpqEFwCUiUlJECgEtgErevp4iMl9E3haREmGMwRhjTCbClgicc4uBgcBEYAIwF0gGhgLVgNrAemBQWs8Xka4iMlNEZm7evDlcYRpjTMwLa2exc+4t51wd51wDYBuw1Dm30TmX7Jw7DLyJ9iGk9dxhzrkk51xS6dKZNnEZY4zJpnCPGirj/ayM9g98ICLlQw65Fm1CMsYYE5BwdhYDfCYiJYGDwJ3Oue0iMkREagMOWAl0C3MMJpu2/rOVZevWknDgEBJ0MCZPOgwkFCvMOdVqEBdn05Zyq7AmAufcJWlsuzmcr2lyxtZ/trJwzSruquZYVAgO2f9hkw0FDsOLK/ZQZO1qqleuEnQ4Jh3239ukadm6tdxVzTG/iCUBk3374+CpSo41Gzfw2c9TsRURc6dwNw3lXhMmwM8/Q1wc9O+v2774AmbPPvK4xER4+OGIhxe0hAOHWFQo6ChMNNiQH4rGJfDO9B8pXqgojWvXCTokc5TYTATbtkGbNrB7NyQkpCaCsWPh7bePPLZ48ZhMBIJdCZickSwQh1C8cBEWrF5hiSAXis3/6kOHahKYNw8OHkzdPnw4HD585O2ff3TfypVw112wf38gIZsc8t+34fYnc/7YzEgSLF+TtedMnQkVw1iK647/wpPDUx8PHQVlm0GRS2Drdv25Ym2OvVx8XBz7DhzIsfOZnBN7VwT79sHgwdC8OZx9tv/nTZ4Mr7yiyePzz6FkyfDFaPwZ8RUMeg/+XAvFisC1DeHpnlC8aPrPebiz//Nn5di86PWQK92Dh+CeF2H6O3BODd2264dg4jIRF5tXBI88Ao89lrXn3HYbfPQRzJgBF14If/4ZntiMP4PegweHwHO9Ycf3+gG2aj00vRMOHEz7OYcORTbGvGTjVti3H8445fjPZe9znhN7iSAxEXr10g/zrLrhBr0y2LIF6tWD+fNzPj6TuX93Qb83YMj90PxCyJcAVU6CT56BlX/De+P1uP5vQJsH4KbHoNilMGKsbrsp5EvA/8bCyVdBycbaTFLlavh2RurzU45d+bc274wcC5WvhFKN4am3Us/z6wKofysUbwjlL4eeA9NPSEf7Zwfc+gSc1BxKNIJW96Z93DMjoNo1ULQB1LoePp+Sum/5Gri0K5xwqcZ2Q1/d7hzcPQjKNNX34KwbYMFy3depPzz6GixdBTVb67bijeCyO/R+aHPW/gNw30v6u5dtps1Ke/fpvpQmrIEjoNzl+ruYPCW2EsGkSfDWW8f3jeXii2H6dGjYEKpWzbHQTBb8PB/2HYDrGh25vUghaHERTJqRum3M99CmMWyfAh2aH3n8ohXQYyC8/x9YPwF27IJ1mzJ+7R/nwpLPYPJQGDAcFv+l2+Pj4cV7YMu38Ms7MPk3eO1Tf7/PzY/Dnn2w8BPYNAnubp/2cdUqwg/DYcdU6NdFk9T6LbrvsaHQrC5smwJrx8NdN+j2idNh2hxYOlqf98kzULL4keetcbK+Nuj79N3rx772Q0M0Ycz9AJZ/Dus26++fYsNW+OdfWPUVDHvE3+9tco3o7yP444/UDt6HH9YRQ506Hd85q1eHT73/5Lt36/2OHUGifP5twxrHbmu7DXpshj0CLaofu7/TVr1tiYc21Y7d330z3LAN1uSDSj6/QW/ZDqWK64ivo5UvBbMWpz6ufza0aqj3CyYeeeyoyXD1JXBxbX084A54+aOMX7tfFz3POTXgnOowbymcXhXqnJ56TJWToNt18P1s6JPOh3qK9Vvg659h62QoUUy3XZrOqJrrm6Tev6EZPD1Cr0SuaahXRas2wN+boWLZ1N8pXwLs3AN/rIQLztBYs8o5GPY5zP8ITjxBtz18K7R/VPtkAOIEnugGBfJn/fwmcNGfCFq3hkWLUh8PHarf3nLKG2/Avfdq38GQIWl/OJmcVaq4JoNDh459v9dv0f0pKpVN/zx/bz5yf6FEKHlCxq9dLmSQQKFE2LVX7y9dpZ2tMxfrt/tDh45MDulZswFOLJaaBDLyv7HwwgfaTAX62lu26/1ne8Fjr8MFHfVc93aAztfAZedDz7Zw50DtQ7nuMni+t3au+7V5m/5OdW5K3eYcJB9OfVy6BCQW8H9Ok6tE/6fW4MGwc6feT0yEZs1y9vx9+sDmzfDMM7BqFXz8MRTNYNRKXjZ1afr7CrmM95dKzni/36sB0G/5BfLB6CnQtmnq9l179Nv1f+9M3ZbRVVr5UrAkZN2Ovftg6w7/cYTq/gycWxM+fAqKFoaXPtArjsxUKqdNKtt3ZjzaadV66PKUNknVP0u/zNRurxW7AMqVgjcf1fs/zoUmPaDBeXBqJejVTm+b/oG2D8Fz78KT3f3/bqWKQ8EC2nxUoUzax0T71XCUi/4+giZN4Npr9XbFFTl7NQA6M/npp2HYMJg4ERo0gHXrcvY1zJFOKKJNNHc9BxN+1qGPK//WD7mKZeBmn2Pv2zSGr36An+dpx27/YfpNNzt27oZihbWf4o+VOibfj/Kl4IoLocczsO1f/V2mzT72uN179cO2tHe1886XsCBk5Nqn38LajXq/RFE9Nk7gt4UwY4Get3BB/dae1eJvcXHQ5Vq4+wVNJqB9Kd/8krXzmFwr+hNBpHTpAuPGwa5dYJNmwu+BjvDfHjqSpdilULeTNvNMHuq/nfqMajryqN3DUL65foiXOTF77dzP94EPJuiIni7/0TZ8v94doG35p7XR0T0vfXjsMbVO0eae+p111M7vy+Gic1L3/7ZQ34Mil0DLe2DwvXBKRfh3t8ZTopE3OuoEuD8bdR8H3qVXF/Vu1fe7SY8jr6ZMniZ5oQhUUlKSyzNrFqe0Wx8+rJPPzj036IiyZdasWSTFWiWAXXt0+OSy0VC1QtDRRJWZs+Dd2T9RvkRJHmzTIehwYoaIzHLOJWV2nF0R5LSUzstXX4Xzz9cmI5N7fTVNO0J379Wri7Oq6agfY2KIJYJw6dQJmjaFbt2gb1+9QjC5z5jvdSLXSc1h2Rr46L/W8WlijiWCcClaFL76ShPBM89A5crw9de674cfoFq1Y2/Tpun+CRPS3j9rlu7/7LO09y9Zovv/97+096/NuQJiUWP4Y7B9qpapmDwUalYJOiJjIi76h48GKSFB5y3UqaMf8imF6ooXT7vERXFvREjJkmnvL+aNNS9dOu39hbwFBMqXT3t/AW+c96BBULs2NG6ctd/HGBOVrLM41uzbB+edB4sXayG9559PTUAhYrKz2ISNdRYHwzqLTdoSE7WJ6cEHYcQIqFULxowJOipjTIAsEcSiggW132LGDChTBtq2tf4DY2KYJYJYVqcO/PYbfPcdVKyo26ZOzf7sWmNMnmSJINblywcXXaT3J0+GRo2gRRiXR8wNRnwFF98WdBRHSlkbIFxCl53cuw+uvlvXLrj+QXj/a2h2Z8bPN1HNRg2ZVA0bapG+vn2DjiRzVa6Gjf9AfJyWhmheH155QO8HpWFXuKkF3N4quBjSE7rs5KjJuiLZ1smpEyA7XBFMXCZXsCsCkyo+XldvW7gw6Ej8+eoF/YCb+z7MWQJPvxN0RHnDqvW6GE1OlExPTj7+c5jAWSIwx6pSJegIsqZcKbi8HswNKXO9Yxfc8jiUbqLF1v4z/MjZ3c7pcpInXAqntYbJv6buC12uEo5csnLffr1fsrEuS3n+Lfrt+pFX4Ye50PNZbYbpOTDtWH+cCxd21udWulKbqY627V+4qo/GXqKR3k+pLAr6nFO8JSurttSmHUh/uUpIXXay3xu6stjHEzXOt744tqnsj5XQtAeceBnUvA4+mZS6r1N/6P40tOgFhS+GKTasOxpY05DJ+9Zu1HUILjs/ddtdz2oyWDFG1xho1lNLPt/mNdvMWKhlqLdMhtHfwXX3w19fpq7AlZ6RY/W8a8bpmghzl2qt/qfuhJ/mZdw0tGo9XNELhj0MbZro2strNh573OHDcOvVuqxkcjJ0HqAJ5otBWhOp1/Pw20idBb1+i655DKnLVU55Xctqz1x87Lmf6AYCLF8L7z2p20KT0e690PROGNANvn5Zq5w2vRPOrKYVUEGrrI4fDGNf8r8us8nVLBEY36Y07HrMtk/aNmVoj+spuGcf41v0Omb/iE5XM7LT1ZTcsp1RbR44Zv/Q7m345IZmVFyzgbWVymUtoFb3aV2gXXs0CTzRTbcnJ8NHE3V93aKF9XZvB3h3fGoiKFNCl5EU0ZLRg96DcT/CzVdm/Jr5EjSxLF8DZ1f3twpZig8mQJML4EZv7eSSxY9dPzhle+uQWd+PdIZGd6Q+jhNdi6ByOU1u5UulxpbWcpVZMfYHqFIebm2pj889DVpfpusd9PP+/a+5FC7yzm2rkkWFsDYNiUhvEVkgIgtFpI+37UQRmSQiy7yfJcIZg4liXzwPO6fB1De0OSNl2cYt23UhlpPLpx57cnldcD1FhTJHFpc7ubx+gGbm5iu1Gardw1qo7oHB+lp+rNmoC9BnZs8+6PaUNmkVuxQadNUVzJKTdXGZj5+G1z/TNRSu7K2/O+hylc7pcpVntIW3szFRcNV6XcimeMPU2/sTdHH6FBkt/2nypLBdEYjImUAX4ALgADBBRMYCXYHJzrlnROQh4CHgwXDFYXJOo6npl9TeWygxw/1bSxXPcH+WrwZCXVoHOl2lZaS/GKRLK+ZL0A+1lOaM1RugQunU56zbpB+aKclg9QZo2UDvFy6oH8YpQj8E8yXoN+N+XXVVtBa9oebJeqWRWdXSSmXhVx8d8YPe00VfZozQ/o+5S+DcDqnzOy6vr7e9++DRobrwzA/DM16u0q9KZeHS82BSBkNZrTpr1AnnFcHpwAzn3B7n3CHge+A64BpgpHfMSCCsY+3mzoVfftHbnDnBzJXaskVvJoz6tIdJM2DeUh391LYpPPKaLiG5aj288L6236fYtA1e/ki/zX/6LSxeCS28+RS1a2jT0sFDMHPRkWsPT5mp7ebJybo0Zb6E1KUfy54IKzJYprTDFfDtr9r5eugQbN2uH/JH27kbCibqGsb/7IAn3kzdt3ErjJmqbfkF8utw2ZTXT2+5yqy46hJYuhreHae//8FDuvrZ4r+ydh6Tp4QzESwALhGRkiJSCGgBVALKOufWe8dsAMJ6ndmhgxbivPBCrbX2YRqrAIbLIa/FYNo0OOkkuPlmsNp5YVK6BNxyJQzwPjSH3K/f7E+5Bi6+Hdo3h84tU4+vewYsW62jax55DUYNTG2vf/IO+HOtjtjp94Y+N8WGLdDmAW2yOf16/facskZy7xs1aZRoBL2eOzbGyuW0k3XQe3BiY6jdAeYtO/a4Pu31236pJro0ZPP6qfsOO3jhA22WOvEy+H4WDH1I96W3XGVWFC0ME1/RRHhScyh3OTw4BPbb8qvRLKzVR0XkNqAHsBtYCOwHOjnnioccs805d0w/gYh0RZuRqFy5cp1Vq7K3PuqPP8Lu3Xr/nnv0y+K8eeG7uj1wAEaN0nlZV1wB/fvD3r1w3326TMCuXVC/PvTuDW3aaDy5kVUfNTnJqo8GI1dUH3XOveWcq+OcawBsA5YCG0WkvBdkeWBTOs8d5pxLcs4llS5dOq1DfLn4Yrj8cr0NGADt2sHBMIx427wZ/vMfHYLfoQNs2waneM3TBQvqypXr1sFLL8GmTfDAA6nNVId89jUaY0w4hHX4qIiUcc5tEpHKaP9APaAq0BF4xvsZsRrIrVuH79w9euiVwOWXw1tv6c+4o9JssWJ6JdCzJ6xerRM79++H00/XNWJ694YzzwxfjMYYk5Zwzyz+TEQWAV8BdzrntqMJoKmILAOaeI8j5tAh+Ogj7UTOruRkGD1a67Mt85p4BwyARYt0lckrrjg2CYSKj4eqVfX+7t26tPH778NZZ2lC+PJLm7lvjImccDcNXeKcq+WcO8c5N9nbttU519g5V90518Q59084Yzja3r3Qvbs242TVtm26oFe1anp1sXIlrFmj+04/XW9ZdeKJ8MYbep5nntHEcs018NNPWT+XMcZkR8zVGipaVJtxRo9O/Tbvx759UL063H+/9gOMHg3Ll8Nll+VMXCVL6qJhK1bAuHFwySW6/ZFH4K67YOnSjJ9vjDHZFXOJAPSDNX9+SEqCSiFzbe65R4d5ht5SvuUnJsJzz+lchKlT4dprwzPiJyFBlwNIGdW0Y4deMdSsCVdeCRMnRmYuxGGgwOFMDzMmUwmH4TC22FFuFpO1hsqVg+HDdXx/aFv+Oefo8M5QhULK2996a2TiC/XKK/Doo5oMhg7VTuiHHoKnnw7v6yYUK8xLK/bwn0qODfkh2SaTmmxIOAy3bDjMloMHcM4Rn1HnmQlMWOcR5JSkpCQ302ZisX8/fPKJrjBZqxbMnq0T5O68M+crRx8+fJhVf69j5Ya/KUI8cVZWwGTDYRxbDu5n3uoV/PH3GpqfV5d2DRpn/kSTI/zOI4jJK4K8qkABnZ2c4pdf4MUX4YUXtIO5d29o0CBnJsvFxcVRtWIlDsfH8dznH3Lg0EEi+qVhxV+wZAls3gLJ3kSLggXh+ut1VbJ/d2p7Xf584Yvh3506FGz5cp2QUuVkOJQMEgfxUZ4Ykw/r+7xzN3w2CsqW1XbSypWzXLbCOXDOcUrZ8lx1fv3Mn2Aizq4I8rg1a+C112DYMPjnH11t8rvvcnbm9Kbt21i1eQMH/FbZzEnJydqDvnAhbNoIXb1S03f30XodVaro5VGtWnD22VD1lON8QQe//aaXXr9Mh4R4aNIEOtyUOuY3luzZreOZP/sM1m/QhNC6NbS6BgoV9n2awomJ1KhQiUIFEsMYrDma3ysCSwRRYs8enYuwZ49eGTinVwo33qid3lHn+++1k2fGDJg+HbZu1SFck70CcS++qEmibl1/b8Dhw9phdPgwnHaa9tJ37w533KGdSrEuORm++kprp/z0k46dPukkba8sYGsS5FaWCGLcnDnalxAfr60pvXvrZ2JUck6vGnbt0h7//fuhRAmdNAI6NKxuXejUSYdehVq1SnvkP/8c5s/X0QFLlmgSsQ+4tK1dCxW9YnaNG+sfWe/emc+kNBGXK2oNmeCce67Ok+jZU+cl1Kunt9Wrg44sDER0lt855+jjAgW0neyXX7S400UXwaxZqRNH1q3TUrTNm2tBqBdf1Mc7vCUfa9a0JJCRlCRw+LAmgoUL4aqr9EpqyBDYuTPY+EyW2RVBDNi5E0aO1GbeiRMhXz69uq9RA46jnl/ek9L8s3ChfoNduVIvl3r0OHJCicmagwe10NbLL2sz3YsvQp8+QUdlsKYhk4HkZG352LwZ2rfXz8SUL9PGHJdff9UrqhNOSP320bu39t/YEOSIs6Yhk674eL0y6NwZPv4YatfW0UZW38gctwsu0CQAujjH9Ok66uqss3Ro2549wcZn0mSJIEadfroOO127VktnrFyZOqt661bYvj3Q8Ew06NJFO6XeeUfbI7t1g6uvDjoqkwZLBDGuRAldPW35cmjWTLc98wxUqKBN53/8EWx8Jo9LTNTRWrNn65DfRx/V7du36wpOP/4YzELi5giWCAygxe5SmnBvugnattUFdk4/XQfXfPNNsPGZPE5Ep703aqSP58+H8eO1zO755+s6rvv3BxtjDLNEYI5xzjl6Nb9mjS64M28evPtu6v6U4fnGZFuDBtouOXSo9ht07Agnn6zDfk3EWSIw6SpTBh57TOdcvfSSbps3D8qX15LdK1YEG5/J4woX1pnbCxfq6IXbb9eVmkATxKxZwcYXQywRmEzlzw+lSun9xERdL2HIEDj1VGjVCqZMsWZecxxEdL3WlGUDd+/WFZmSkrTY36ef6hqzJmwyTQQi0ltEiol6S0Rmi0izSARncp+aNeGDD3SU0cMP65DTli1tMqnJQYULw19/6cS09eu1w6pqVV0RyoSFnyuCzs65f4FmQAngZiK84LzJfSpU0C9wq1fDpElQrJheFTRpogli7dqgIzR52gkn6OzkpUthzBgtX3GKV1l23jxYsCDY+KKMn0SQMh2wBfCuc25hyDYT4woW1BpGoPMQihWDgQN15nK7dlrux5qNTLbFx+sl56RJuhYCaMfVWWdpnaMvv9Sp8ua4+EkEs0RkIpoIvhGRouiStsYcoWhRGD0a/vxTv8xNmAAXXqhf6IzJMe+8o2u1Ll2qKzLVqKHlLEy2+UkEtwEPAec75/YA+YEAVu81eUWVKvD889o89PrrWp0YdF7CgAGwcWOg4Zm8rmRJXbh7xQqtkVKuHGzYoPsOHEitMmt8yzQROOcOAxuBWiLSADgDKB7uwEzeV6SIVhVIqej866/Qr59e4XfsqJNNjcm2fPm0I/mnn3R6POgIoxo1dN2JiROtXdInP6OGBgI/AY8C93u3+8Icl4lCb7yhJSu6dNGilHXqwL33Bh2ViQrx8fqzcWP9tjFzJlx+OZxxhl6W2vDTDGVahlpElgBnO+cCm/9tZaijz/bt8PbbWvn0sst0rZj33tMkkTKnyJhs279f150ePBj27YPff9f5Cjt3amdWjMjJMtQrgHzHH5IxqYoX19nJl12mj8eP12bfihW1OWnhwmDjM3lcgQJw883w2286/yAlCZx8MrRpo+tdW7PR//OTCPYAc0XkDRF5OeXm5+QicreILBSRBSLyoYgkisgIEflLROZ6t9rH9yuYaNCliw4Pb99e64+deaZ2MtvIQHNcRFKnxR86pN8ypkyBSy/VtskRI/SKIcb5aRrqmNZ251yG47VEpALwI1DLObdXRD4BxgMNgbHOuVF+g7SmodiyZQu8+aYOBBk8WLeNHq2T1YoVCzY2EwX27IH339c/roULtabReefpFUKUraLmt2koIbMDnHMjRSQ/UMPbtMQ5d9BnHAlAQRE5CBQC/vb5PBPDSpWCvn1TH69YAa1ba9Nu585w1126Vr0x2VKokF6C3n67Nh2dd55u79pVk0Tv3rrSWgzxM2qoIbAMeBV4DVjqDSPNkHNuHfA8sBpYD+xwzk30dj8lIvNF5EURKZDd4E1sOOUUHXrasqWuqla9ui50ZdVPzXEROfID/8QT4auvoG5dqF8fPvwQDvr9zpu3+ekjGAQ0c85d6pxrAFwOvJjZk0SkBHANUBU4CSgsIjcBfYHTgPOBE4EH03l+VxGZKSIzN2/e7OuXMdHr/PN1VNGqVVphYMEC7XAGXV3NlsI1x23gQJ0FOXiwtk+2bw9PPBF0VBHhJxHkc84tSXngnFuKv1FETYC/nHObvaak0cCFzrn1Tu0H3gHSvAZzzg1zziU555JKly7t4+VMLChfXv9v/vmnfoFzDm68UUcbPfigFsEzJtuKFYNevWDJEhg7VpuQQEcede6sIxqikJ9EMFNEhotIQ+/2JuCn53Y1UE9EComIAI2BxSJSHsDb1gqwMoImy+JC/nJfeEGHoT7/vDYjXX+9zicyJtvi4nR28skn6+MlS+Cjj3TiS8OG8PnnUTWkzU8i6A4sAnp5t0Xetgw552YAo4DZwO/eaw0D3heR371tpYD/ZCtyY9Bm3ksugVGjtM/gnnvg229hzhzdv2+fLYVrckC3btps9OyzulbCddfpH16UyHT4aG5gw0dNVuzeDQkJOqdoyBBdN+GOO6B7d61PZsxxOXRIy1/v2QM33aSPH3sMOnXSlZtykeOeWeyN+0dEfvdG+Bxxy8lgjclJhQunFro77zztaB4wQIvd3XyzNRuZ45SQoFcEN92kj+fM0fbJ007TWZATJsDhvFWpP90rAhEp75xbLyInp7XfObcqrJGFsCsCc7yWLYNXXtFS9rVra4UBY3LMpk1aVfG113QmZM2a2kZZsWKgYR33FYFzbr13t4dzblXoDeiRU4EaEwnVq+uowLVrdV0E0P+vDz6oJeyNOS5lymjz0KpVOmv5nHPgpJN037hx2q+Qi/npLG6axrYrcjoQYyKhWDFNCqCjA599Vq/mt28PNi4TJfLn1/kHH3+sI48OHdJhp9WqQatWWucoF/bLZtRH0N0b3XPaUf0Df6EjfozJ026/XWuOTZsGF12kX+aMyVEJCVrLqG9f+PFHHedcu7YmhFwkoyuCD4CrgTHez5RbHedchwjEZkzYdeyofXvr1mllgd/tK47JaRUrwlNPwZo1MHy4XhEULKj71q7VW8Ay6iPY4ZxbCQwG/gnpHzgkInUjFaAx4da4Mfz8s35RC7hvz0SzggXhttt0dnK9erptwACoWhXatYNffgms2chPH8FQYFfI413eNmOiRq1aemVQooROQPv006AjMlErtNR1375a0mLCBLjwQr0sHeW7Qn+O8ZMIxIWMMfUWs8+0fLUxedXrr+ua6HffHVVVBExuVLUqDBqkzUOvvgr//pvaf+CcFr+LAF9LVYpILxHJ5916o8tXGhOVevbUkvQvvaSrGlplUxN2RYpAjx6waJEOZQPtXO7TJyIv7ycR3AFcCKwD1gJ1ga7hDMqYIMXHaxIYPBjGjIFGjWDjxqCjMjEhLk6nxgNUqgT9+kXkZf2sULYJaBeBWIzJVXr1gipV9IvaP/9A2bJBR2RiSpUqEXupdBOBiDzgnHtWRIYAx3RlO+d6hTUyY3KBli2hWTNITNQm2yVLtKQrLzIOAAAYzklEQVSMMdEko6ahxd7PmcCsNG7GxITERP05fDicfTb873/BxmNMTkv3isA595X3c2TkwjEm97r+el2bpGNHLR3z+ONHjgQ0Jq/KqGnoK9JoEkrhnGsZloiMyaWKF4evv4auXaF/f10I5803tbyMMXlZRk1Dz6ML1/8F7AXe9G67gD/DH5oxuU/+/FrKesAALTI5Y0bQERlz/DJdoUxEZh5dzzqtbeFk6xGY3GjZstRKpnv2QKFCwcZjzNGOez2CEIVF5JSQE1cFCh9PcMZEg5QkMH683v/112DjMSa7/CSCu4GpIjJVRL4HpgCRme5mTB5wyim6NGbDhvDFF0FHY0zWZZoInHMTgOpAb6AXUNM59024AzMmrzjtNJg+Hc46S5eyHTw46IiMyZpME4GIFALuB3o65+YBlUXkqrBHZkweUqaM1gpr1UrLw0yaFHRExvjnp2noHeAAUN97vA74T9giMiaPKlRIy1d/8gk0aRJ0NMb45ycRVHPOPQscBHDO7QFsGo0xaYiP14lnIrB4MTRtCuvXBx2VMRnzkwgOiEhBvMllIlIN2B/WqIyJAmvW6Mpn9erBwoVBR2NM+vwkgn7ABKCSiLwPTAYeCGtUxkSBZs1g2jQ4cEAXn5o8OeiIjElbholARAT4A7gO6AR8CCQ556aGPTJjokCdOjr7uFIlaN48dfEpY3KTDNcjcM45ERnvnDsLGBehmIyJKpUrw08/wVNPQf36mR9vTKT5aRqaLSLnZ+fkInK3iCwUkQUi8qGIJIpIVRGZISLLReRjEbGSXSbqnXCCrkCYmAjbtsHDD8N+62kzuYSfRFAX+EVE/hSR+SLyu4jMz+xJIlIBnYCW5Jw7E4hHVzobCLzonDsV2Abclv3wjcl7vv4ann5a+xD++SfoaIzxsVQlcPlxnr+giBwECgHrgcuA9t7+kUB/YOhxvIYxeUr79jq8tFMn7UQeP17LVBgTFD8lJlYBJYFrgJZASW9bZs9bh5ayXo0mgB3oymbbnXOHvMPWAhWyF7oxedeNN8K338KmTXDeeTYT2QTLT4mJx9Fv7iWBUsA7IvKoj+eVQJNHVeAktGJpc7+BiUhXEZkpIjM3b97s92nG5BmXXKIjipo31zpFAL/8At9/r+sjGxMpfvoIOgDnO+f6Oef6AfWAm308rwnwl3Nus3PuIDAauAgoLiIpTVIV0ZIVx3DODXPOJTnnkkqXLu3j5YzJe6pX1+Uvy5XTx//9r1YxPe88XQBn375AwzMxwk8i+BtIDHlcgHQ+vI+yGqgnIoW8+QiNgUVoGes23jEdgTH+wzUmun38MQwbBgcPQufOOvT01VeDjspEOz+JYAewUERGiMg7wAJgu4i8LCIvp/ck59wMYBQwG/jde61hwIPAPSKyHG1ueus4fwdjokahQtClC/z+u85EDp13sHevLX5jwsPPUpUdM9rvnBuZoxGlwZaqNAbeegtuvx3q1oXevaFNG8iXL+ioTG7md6nKTIePRuKD3hiTubZtdW3kIUN0COp990GPHvDgg5DgZyC4Menw0zRkjMkFihaFu+6CP/6AcePgzDNhzBgtfQ2wYUOw8Zm8yxKBMXlMXBy0aAHffKNDTUV0hnK1atCoka6bnJwcdJQmL/Ezj+B6P9uMMZFXsKD+zJcP+veHFSvg2mvh1FNh0CDYsSPQ8Ewe4eeKoK/PbcaYgBQtCvffD3/+CaNGadnr++6Dv//W/YcOZfx8E9vS7WISkSuAFkCFo4aJFgPsz8qYXCghAVq31tuyZTphDaBDB7066N0bLr9cm5eMSZHRn8PfwExgH1ojKOX2JcdXiM4YEwEpSQCgdm2YN0/7Fk4/XSep7doVXGwmd/Ezj6AYsNs5l+w9jgcKeIvYR4TNIzDm+B04oM1GgwfrxLTHHoMBA4KOyoST33kEfi4QJwIFQx4XBL7NbmDGmGDkz6/zD2bM0OJ23bvr9nHjoFUr+O23YOMzwfGTCBKdc/9/EendLxS+kIwx4VavHpQvr/e3btWlNBs0gGnTgo3LBMNPItgtIuelPBCROsDe8IVkjImkW26BxYuhShW4+mqYMyfoiEyk+ZmY3gf4VET+BgQoB9wQ1qiMMRFVqhRMnAgXXaTrI8yfD2XLBh2ViRQ/tYZ+E5HTgJrepiXe+gLGmChSqZKulPb551CmTNDRmEjyM7O4EFo6urdzbgFQRUSuCntkxpiIq1kTHnpIy1YsWaL9Byb6+ekjeAc4AKRURl8H/CdsERljArdvHzRpAldeafMNYoGfRFDNOfcscBDAmz8gYY3KGBOoxER45RUdUnrddbB/f9ARmXDykwgOiEhBwAGISDXA/iyMiXLXXAPDh2u/wc03W0XTaOZn1FA/YAJQSUTeRxeg7xTOoIwxucOtt2qJ6/vu02Uz77476IhMOGSYCLxF5/8ArgPqoU1CvZ1zWyIQmzEmF7j3Xh1K2rp10JGYcMmwachpIaLxzrmtzrlxzrmxlgSMiT033aRrH2zfDh9/HHQ0Jqf56SOYLSLnhz0SY0yuN3AgtGsHI20l86jip4+gLtBBRFYBu9HmIeecOzuskRljcp3+/WHWLLjtNiheXDuUTd7nJxHY2gPGGAAKFIDRo6FxY7jhBpgwARo2DDoqc7wybBry1h74xjm36uhbhOIzxuQyRYrA+PFQrRrcdZcNK40GGV4ROOeSRWSJiFR2zq2OVFDGmNytZEktUnf4MMTHBx2NOV5+moZKAAtF5Fe0jwAA51zLsEVljMn1KlTQn8nJ0K8fdOumhetM3uMnETwW9iiMMXnWX3/BkCHw2Wfwww9a0trkLZkOH3XOfY9OKivq3RZ724wxhlNPhS+/hJUroUUL2Lkz6IhMVvkpQ90W+BW4HmgLzBCRNj6eV1NE5obc/hWRPiLSX0TWhWxvcfy/hjEmSJdeqhPNZs+Ga6+1InV5jejk4QwOEJkHNHXObfIelwa+dc6d4/tFdPTROnROwq3ALufc836fn5SU5GbOnOn3cGNMQP73P+jeHaZMgQsuCDoaIyKznHNJmR3nZ2ZxXEoS8Gz1+bxQjYE/bdipMdHtllvgzz8tCeQ1fj7QJ4jINyLSSUQ6AeOAr7P4Ou2AD0Me9xSR+SLytoiUSOsJItJVRGaKyMzNmzdn8eWMMUEpV05/vvkmPPxwsLEYf/x0Ft8PvAGc7d2GOece8PsCIpIfaAl86m0aClQDagPrgUHpvO4w51yScy6pdOnSfl/OGJNLzJkDTz8Nzz0XdCQmM+kOHxWRU4GyzrmfnHOjgdHe9otFpJpz7k+fr3EFMNs5txEg5ad3rjeBsdmO3hiTaw0ZomsZPPCATkDr3DnoiEx6MroieAn4N43tO7x9ft1ISLOQiJQP2XctsCAL5zLG5BHx8dp53KwZdOkCn38edEQmPRlNKCvrnPv96I3Oud9FpIqfk4tIYaAp0C1k87MiUhtd+nLlUfuMMVEkf34tUtekCSxbFnQ0Jj0ZJYLiGewr6OfkzrndQMmjtt3s57nGmOhQuDB8/70mBYBDhyDBT00DEzEZNQ3NFJEuR28UkduBWeELyRgTbVKSwPTpUKsW/PFHsPGYI2WUl/sAn4tIB1I/+JOA/GjbvjHGZEmpUrBjBzRtCj/9BJUrBx2RgQyuCJxzG51zFwJPoG35K4EnnHP1nXMbIhOeMSaanHoqfPMN/PuvdiLbFKHcIdOWOufcFGBKBGIxxsSA2rVh7FhNBC1awHffQdGiQUcV27JaKsIYY47bJZfAqFFQvXpq/4EJjvXdG2MCceWVegPYvl2XwLTRRMGwKwJjTKB274aLLtIVzjIphmzCxBKBMSZQhQtDmzbw9tvw4INBRxOb7ELMGBO4/v1h61YtUFeokK6BLBJ0VLHDEoExJnAi8PLL2kz0xBNQoAD07Rt0VLHDEoExJleIi9PmoTPPhA4dgo4mtlgfgTEm1xCBe+/VxW0OHYLevWH16qCjin6WCIwxudLSpTByJNStC7OsullYWSIwxuRKtWppPaL8+aFBA/jqq6Ajil6WCIwxudYZZ8CMGXD66dCqlfYhmJxnicAYk6uVK6frGbRtC+ecE3Q00ckSgTEm1ytcGD78EOrU0cfvvw979gQbUzSxRGCMyVMWLICbb4ZGjWDjxqCjiQ6WCIwxecqZZ+o6yL//DvXr22pnOcESgTEmz2nVCqZO1ZnI9etrH4LJPksExpg86YILdA3kk06CdeuCjiZvsxITxpg8q2pVmDMndXGb33/XpiMrWJc1dkVgjMnTUpLA4sWQlASdO8OBA8HGlNdYIjDGRIXTToNHHoERI+CKK3TVM+OPJQJjTFQQgccf1/pEP/ygq56tWhV0VHmDJQJjTFS55RaYOBH+/hvefTfoaPIG6yw2xkSdhg1h3jyoWFEf79oFRYoEGlKuFrYrAhGpKSJzQ27/ikgfETlRRCaJyDLvZ4lwxWCMiV2VK+tiN6tXQ40aMHhw0BHlXmFLBM65Jc652s652kAdYA/wOfAQMNk5Vx2Y7D02xpiwKFVK1zTo00cXuklODjqi3CdSfQSNgT+dc6uAa4CR3vaRQKsIxWCMiUGFCsGoUZoIXn4ZWrfWGckmVaQSQTvgQ+9+Wefceu/+BqBshGIwxsSo+Hh48UUYMkQXuOnfP+iIcpewdxaLSH6gJdD36H3OOSciLp3ndQW6AlSuXDmsMRpjYkPPnrrITd26+tg5m4UMkbkiuAKY7ZxLKRi7UUTKA3g/N6X1JOfcMOdcknMuqXTp0hEI0xgTCxo31hFEu3ZBkybw3XdBRxS8SCSCG0ltFgL4Eujo3e8IjIlADMYYc4QdO3Q9g8sv10losSysiUBECgNNgdEhm58BmorIMqCJ99gYYyKqQgX48Ue49FLo1An69dOmolgU1j4C59xuoORR27aio4iMMSZQxYvD+PHQrRsMGACHD8OTTwYdVeTZzGJjTEzLnx/efhvOOEOHlsYiqzVkjIl5InDffbq+weHD0Lcv/PZb0FFFjiUCY4wJ8ddf8OabugLahRfCxx/DwYNBRxVelgiMMSZEtWqwYoXWJtq0Cdq1g1NO0dXPopUlAmOMOUqxYtCrFyxdqjOR69aF6tV136RJ0ZcULBEYY0w64uLgqqu0VlFiog4vvftuOPtsuOwyGDMmOorYWSIwxhifRGDaNBg4EJYvh1at9Eph9OjMn5ubWSIwxpgsOPFEeOAB7Uf49FOdmJbgDcTfvFmbk/IaSwTGGJMNCQnQpo2uj3z11bptyBCoWRNatIBvvsk7M5UtERhjzHFKqWB6553wxBMwZw40bw61asGwYcHG5oclAmOMySFly8Ljj8OqVfDuu1rldOLE1P2b0qy1HDxLBMYYk8Py54ebboJff02tbPrHH3DSSXDddfD997mr2cgSgTHGhIkIFC6s90uUgPvv1yTQsCGce67WONq3L9AQAUsExhgTEWXLwtNPw9q1WsIiOVn7FFLWTw5yPoIlAmOMiaCCBeH222H+fJg7F0p6hfobNoT27WH69MjHZInAGGMCIKJDTQEOHIDzz4dx46B+fS1p8cEHuj0SLBEYY0zA8ueHF17QZqMhQ2DbNujQAd57LzKvb4nAGGNyiaJFoWdPHWE0bhzccENkXtdWKDPGmFwmLk5nJ0fs9SL3UsYYY3IjSwTGGBPjLBEYY0yMs0RgjDExzhKBMcbEOEsExhgT4ywRGGNMjLNEYIwxMU5cbiqKnQ4R2QysyubTSwFbcjCcvM7ej1T2XhzJ3o8jRcP7cbJzrnRmB+WJRHA8RGSmcy4p6DhyC3s/Utl7cSR7P44US++HNQ0ZY0yMs0RgjDExLhYSwbCgA8hl7P1IZe/Fkez9OFLMvB9R30dgjDEmY7FwRWCMMSYDUZMIRKS5iCwRkeUi8lAa+wuIyMfe/hkiUiXyUUaGj/fiHhFZJCLzRWSyiJwcRJyRktn7EXJcaxFxIhLVI0X8vB8i0tb7G1koIh9EOsZI8fF/pbKITBGROd7/lwiuEhBBzrk8fwPigT+BU4D8wDyg1lHH9ABe9+63Az4OOu4A34tGQCHvfvdofS/8vh/ecUWBacB0ICnouAP++6gOzAFKeI/LBB13gO/FMKC7d78WsDLouMNxi5YrgguA5c65Fc65A8BHwDVHHXMNMNK7PwpoLCISwRgjJdP3wjk3xTm3x3s4HagY4Rgjyc/fBsCTwEBgXySDC4Cf96ML8KpzbhuAc25ThGOMFD/vhQOKefdPAP6OYHwREy2JoAKwJuTxWm9bmsc45w4BO4CSEYkusvy8F6FuA74Oa0TByvT9EJHzgErOuXGRDCwgfv4+agA1ROQnEZkuIs0jFl1k+Xkv+gM3ichaYDxwV2RCiyxbsziGichNQBJwadCxBEVE4oAXgE4Bh5KbJKDNQw3Rq8VpInKWc257oFEF40ZghHNukIjUB94VkTOdc4eDDiwnRcsVwTqgUsjjit62NI8RkQT0Mm9rRKKLLD/vBSLSBHgEaOmc2x+h2IKQ2ftRFDgTmCoiK4F6wJdR3GHs5+9jLfClc+6gc+4vYCmaGKKNn/fiNuATAOfcL0AiWoMoqkRLIvgNqC4iVUUkP9oZ/OVRx3wJdPTutwG+c14PUJTJ9L0QkXOBN9AkEK3tvykyfD+cczucc6Wcc1Wcc1XQPpOWzrmZwYQbdn7+r3yBXg0gIqXQpqIVkQwyQvy8F6uBxgAicjqaCDZHNMoIiIpE4LX59wS+ARYDnzjnForIABFp6R32FlBSRJYD9wDpDiPMy3y+F88BRYBPRWSuiBz9xx81fL4fMcPn+/ENsFVEFgFTgPudc1F39ezzvbgX6CIi84APgU7R+AXSZhYbY0yMi4orAmOMMdlnicAYY2KcJQJjjIlxlgiMMSbGWSIwxpgYZ4nARJyItPKqfJ4Wsq2KiLQPeVz7eCo9ishKbwx8Vp/XSUROyu7rZvG1+ohIoZDHu3w+r5WIPJ7DsXwrIiVy8pwm77BEYIJwI/Cj9zNFFaB9yOPaQBAlfzsBaSYCEYnP4dfqAxTK9KhjPQC8lsOxvItW6DUxyBKBiSgRKQJcjE7dbxey6xngEm+C24PAAOAG7/ENInKBiPzi1YX/WURqeueLF5HnRWSBVy/+rqNer6CIfC0iXY7aHi8iI7zn/S4id4tIG7T20vve6xb0riwGishs4HoRqSYiE0Rkloj8kHJV453rZS+2Fd65EJE4EXlNRP4QkUkiMl5E2ohILzThTBGRKSFxPSUi87xib2XTeP9qAPudc1u8x6VF5DMR+c27XeRt7y8i73rv2bKU319EyovINO/3WyAil3in/pIjE7OJJUHXwbZbbN2ADsBb3v2fgTre/YbA2JDjOgGvhDwuBiR495sAn3n3u6NlxVP2nej9XIleZXwL3JJGHHWASSGPi3s/pxKyHoF3ngdCHk8Gqnv366KlSgBGAJ+iX65qoeWNQcuZjPe2lwO2AW1Czl0q5NwOuNq7/yzwaBpx3woMCnn8AXCxd78ysNi73x+tr18QrY2zBk089wKPeMfEA0VDzrUMKBn034jdIn+z6qMm0m4EBnv3P/Iez/LxvBOAkSJSHf3AzOdtb4IuOHQIwDn3T8hzxgDPOufeT+N8K4BTRGQIMA6YmMFrfwz/fzVzIVqaI2VfgZDjvnBalXJRyLf5i4FPve0bQr/9p+EAMNa7PwtomsYx5Tmy1k0ToFZIPMW8OAHGOOf2Anu9170Ara/ztojk8+KdG3KuTWiyiLpyEiZjlghMxIjIicBlwFki4tBvpE5E7vfx9CeBKc65a0WXGZ3q4zk/Ac1F5APn3BG1VJxz20TkHOBy4A6gLdA5nfPs9n7GAdudc7XTOS60imt2Fj06GBJnMmn//9yLJsUUcUA959wRC+p4ieHo+jHOOTdNRBoAVwIjROQF59z/vP2J3vlNjLE+AhNJbYB3nXMnO632WQn4C7gE2ImWhE5x9OMTSC0R3Clk+ySgm2hp8ZRkk+JxtCnm1aMD8UYUxTnnPgMeBc5L53X/n3PuX+AvEbneO4d4ySQjPwGtvb6CsnhVPTN7rQwsBk4NeTyRkMVSRCQ0SV0jIokiUtJ73d9E16fe6Jx7ExiO93uLZo5yaHOViTGWCEwk3Qh8ftS2z7zt84Fkr6P0brTqZa2UzmK0zfxpEZnDkd+Uh6OlgueLVohsf+Tp6Q0UFJFnj9peAV2DYC7wHtDX2z4CeD2lsziN36EDcJv3WgtJe9nLo3+/tcAi73Vmo6vjga6HOyGT5qKjTQPOldS2oF5AktdRvgi9ukkxH30fpwNPOuf+RhPCPO99vIHUZro6wPSUJjYTW6z6qDFhJiJFnHO7vG/mvwIXOec2HMf5BgNfOee+zeCY/sAu59zzWTjnl865ydmNy+Rd1kdgTPiNFZHiQH70m3m2k4Dnv+iIpZy0wJJA7LIrAmOMiXHWR2CMMTHOEoExxsQ4SwTGGBPjLBEYY0yMs0RgjDExzhKBMcbEuP8DVW0AVRporn0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_range), np.array(nb_correct_original), 'b--', label='Original classifier')\n",
    "ax.plot(np.array(eps_range), np.array(nb_correct_robust), 'r--', label='Robust classifier')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Correct predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy.linalg as la\n",
    "from scipy.optimize import fmin as scipy_optimizer\n",
    "from scipy.stats import weibull_min\n",
    "\n",
    "from art.attacks import FastGradientMethod\n",
    "from art.attacks import HopSkipJump\n",
    "from art.utils import random_sphere\n",
    "from art.config import ART_NUMPY_DTYPE\n",
    "\n",
    "def clever_t(classifier, x, target_class, nb_batches, batch_size, radius, norm, c_init=1, pool_factor=10):\n",
    "    \"\"\"\n",
    "    Compute CLEVER score for a targeted attack.\n",
    "    | Paper link: https://arxiv.org/abs/1801.10578\n",
    "    :param classifier: A trained model\n",
    "    :type classifier: :class:`.Classifier`\n",
    "    :param x: One input sample\n",
    "    :type x: `np.ndarray`\n",
    "    :param target_class: Targeted class\n",
    "    :type target_class: `int`\n",
    "    :param nb_batches: Number of repetitions of the estimate\n",
    "    :type nb_batches: `int`\n",
    "    :param batch_size: Number of random examples to sample per batch\n",
    "    :type batch_size: `int`\n",
    "    :param radius: Radius of the maximum perturbation\n",
    "    :type radius: `float`\n",
    "    :param norm: Current support: 1, 2, np.inf\n",
    "    :type norm: `int`\n",
    "    :param c_init: Initialization of Weibull distribution\n",
    "    :type c_init: `float`\n",
    "    :param pool_factor: The factor to create a pool of random samples with size pool_factor x n_s\n",
    "    :type pool_factor: `int`\n",
    "    :return: CLEVER score\n",
    "    :rtype: `float`\n",
    "    \"\"\"\n",
    "    # Check if the targeted class is different from the predicted class\n",
    "    y_pred = classifier.predict(np.array([x]))\n",
    "    pred_class = np.argmax(y_pred, axis=1)[0]\n",
    "    if target_class == pred_class:\n",
    "        raise ValueError(\"The targeted class is the predicted class.\")\n",
    "\n",
    "    # Check if pool_factor is smaller than 1\n",
    "    if pool_factor < 1:\n",
    "        raise ValueError(\"The `pool_factor` must be larger than 1.\")\n",
    "\n",
    "    # Some auxiliary vars\n",
    "    grad_norm_set = []\n",
    "    dim = reduce(lambda x_, y: x_ * y, x.shape, 1)\n",
    "    shape = [pool_factor * batch_size]\n",
    "    shape.extend(x.shape)\n",
    "\n",
    "    # Generate a pool of samples\n",
    "    rand_pool = np.reshape(random_sphere(nb_points=pool_factor * batch_size, nb_dims=dim, radius=radius, norm=norm),\n",
    "                           shape)\n",
    "    rand_pool += np.repeat(np.array([x]), pool_factor * batch_size, 0)\n",
    "    rand_pool = rand_pool.astype(ART_NUMPY_DTYPE)\n",
    "    if hasattr(classifier, 'clip_values') and classifier.clip_values is not None:\n",
    "        np.clip(rand_pool, classifier.clip_values[0], classifier.clip_values[1], out=rand_pool)\n",
    "\n",
    "    # Change norm since q = p / (p-1)\n",
    "    if norm == 1:\n",
    "        norm = np.inf\n",
    "    elif norm == np.inf:\n",
    "        norm = 1\n",
    "    elif norm != 2:\n",
    "        raise ValueError(\"Norm {} not supported\".format(norm))\n",
    "\n",
    "    # Loop over the batches\n",
    "    for _ in range(nb_batches):\n",
    "        # Random generation of data points\n",
    "        sample_xs = rand_pool[np.random.choice(pool_factor * batch_size, batch_size)]\n",
    "\n",
    "        # Compute gradients\n",
    "        grads = classifier.class_gradient(sample_xs)\n",
    "        if np.isnan(grads).any():\n",
    "            raise Exception(\"The classifier results NaN gradients.\")\n",
    "\n",
    "        grad = grads[:, pred_class] - grads[:, target_class]\n",
    "        grad = np.reshape(grad, (batch_size, -1))\n",
    "        grad_norm = np.max(np.linalg.norm(grad, ord=norm, axis=1))\n",
    "        grad_norm_set.append(grad_norm)\n",
    "\n",
    "    # Maximum likelihood estimation for max gradient norms\n",
    "    [_, loc, _] = weibull_min.fit(-np.array(grad_norm_set), c_init, optimizer=scipy_optimizer)\n",
    "\n",
    "    # Compute function value\n",
    "    values = classifier.predict(np.array([x]))\n",
    "    value = values[:, pred_class] - values[:, target_class]\n",
    "\n",
    "    # Compute scores\n",
    "    score = np.min([-value[0] / loc, radius])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clever(classifier, x, nb_batches, batch_size, radius, norm, target=None, target_sort=False, c_init=1, pool_factor=10):\n",
    "    \"\"\"\n",
    "    Compute CLEVER score for an untargeted attack.\n",
    "    | Paper link: https://arxiv.org/abs/1801.10578\n",
    "    :param classifier: A trained model.\n",
    "    :type classifier: :class:`.Classifier`\n",
    "    :param x: One input sample\n",
    "    :type x: `np.ndarray`\n",
    "    :param nb_batches: Number of repetitions of the estimate\n",
    "    :type nb_batches: `int`\n",
    "    :param batch_size: Number of random examples to sample per batch\n",
    "    :type batch_size: `int`\n",
    "    :param radius: Radius of the maximum perturbation\n",
    "    :type radius: `float`\n",
    "    :param norm: Current support: 1, 2, np.inf\n",
    "    :type norm: `int`\n",
    "    :param target: Class or classes to target. If `None`, targets all classes\n",
    "    :type target: `int` or iterable of `int`\n",
    "    :param target_sort: Should the target classes be sorted in prediction order. When `True` and `target` is `None`,\n",
    "           sort results.\n",
    "    :type target_sort: `bool`\n",
    "    :param c_init: initialization of Weibull distribution\n",
    "    :type c_init: `float`\n",
    "    :param pool_factor: The factor to create a pool of random samples with size pool_factor x n_s\n",
    "    :type pool_factor: `int`\n",
    "    :return: CLEVER score\n",
    "    :rtype: array of `float`. None if target classes is predicted\n",
    "    \"\"\"\n",
    "    # Find the predicted class first\n",
    "    y_pred = classifier.predict(np.array([x]))\n",
    "    pred_class = np.argmax(y_pred, axis=1)[0]\n",
    "    if target is None:\n",
    "        # Get a list of untargeted classes\n",
    "        if target_sort:\n",
    "            target_classes = np.argsort(y_pred)[0][:-1]\n",
    "        else:\n",
    "            target_classes = [i for i in range(classifier.nb_classes()) if i != pred_class]\n",
    "    elif isinstance(target, (int, np.integer)):\n",
    "        target_classes = [target]\n",
    "    else:\n",
    "        # Assume it's iterable\n",
    "        target_classes = target\n",
    "    score_list = []\n",
    "    for j in target_classes:\n",
    "        if j == pred_class:\n",
    "            score_list.append(None)\n",
    "            continue\n",
    "        score = clever_t(classifier, x, j, nb_batches, batch_size, radius, norm, c_init, pool_factor)\n",
    "        score_list.append(score)\n",
    "        \n",
    "    return np.array(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "clever_list = clever(robust_classifier, x_test[2], 3, 128, 0.01, 1, target=None, target_sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clever_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
